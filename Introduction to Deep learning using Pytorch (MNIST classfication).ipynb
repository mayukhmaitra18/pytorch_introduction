{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros([2,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8007, 0.5176, 0.7638, 0.1204, 0.2922],\n",
       "        [0.9587, 0.8376, 0.8036, 0.3869, 0.1507]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand([2,5])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8007, 0.5176, 0.7638, 0.1204, 0.2922, 0.9587, 0.8376, 0.8036, 0.3869,\n",
       "         0.1507]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reshaping\n",
    "#flattening\n",
    "\n",
    "y = y.view([1,10])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.5%5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train = datasets.MNIST(\"\",train=True, download = True, transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "\n",
    "test = datasets.MNIST(\"\",train=False, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = True)\n",
    "#batch - how many items at a time do we pass to a model\n",
    "\n",
    "\n",
    "testset = torch.utils.data.DataLoader(test, batch_size = 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([1, 2, 2, 1, 8, 7, 7, 7, 6, 0])]\n"
     ]
    }
   ],
   "source": [
    "#iterate\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][4], data[1][4]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(data[0][4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10c05a550>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][5].view(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "#check balance of data\n",
    "total = 0\n",
    "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)] += 1\n",
    "        total += 1\n",
    "\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666\n",
      "1: 11.236666666666666\n",
      "2: 9.93\n",
      "3: 10.218333333333334\n",
      "4: 9.736666666666666\n",
      "5: 9.035\n",
      "6: 9.863333333333333\n",
      "7: 10.441666666666666\n",
      "8: 9.751666666666667\n",
      "9: 9.915000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F #you'll have to always parameters in function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() #initialize the parent class using super\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) #final output will be equal to number of classes\n",
    "    \n",
    "    def forward(self, x): #defines how the data will flow through the network\n",
    "        x = F.relu(self.fc1(x)) #tells if the neuron is firing or not (value between 0-1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim = 1) #log softmax will give us probability distribution\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0098, 0.2941, 0.3528, 0.1466, 0.3002, 0.0163, 0.4673, 0.9709, 0.2884,\n",
       "         0.9012, 0.2445, 0.5313, 0.4748, 0.3627, 0.3412, 0.7369, 0.9975, 0.0184,\n",
       "         0.1742, 0.5723, 0.5118, 0.9312, 0.5136, 0.7099, 0.8388, 0.1823, 0.0623,\n",
       "         0.6783],\n",
       "        [0.1752, 0.9895, 0.8069, 0.5180, 0.8805, 0.2260, 0.9596, 0.3437, 0.4300,\n",
       "         0.2909, 0.9095, 0.5705, 0.2284, 0.5020, 0.5313, 0.2017, 0.9862, 0.5391,\n",
       "         0.3112, 0.1813, 0.5322, 0.3014, 0.3203, 0.1452, 0.8551, 0.2437, 0.3650,\n",
       "         0.9748],\n",
       "        [0.5293, 0.0657, 0.8641, 0.5029, 0.1853, 0.3283, 0.0529, 0.8610, 0.7077,\n",
       "         0.7729, 0.8558, 0.9478, 0.0654, 0.5087, 0.6108, 0.2821, 0.0462, 0.4402,\n",
       "         0.1478, 0.5965, 0.3807, 0.7659, 0.7507, 0.8290, 0.6167, 0.6277, 0.1119,\n",
       "         0.2441],\n",
       "        [0.7953, 0.1342, 0.8838, 0.5232, 0.8684, 0.9617, 0.6607, 0.7962, 0.3779,\n",
       "         0.5362, 0.0611, 0.0535, 0.8445, 0.9776, 0.9608, 0.2462, 0.9608, 0.4063,\n",
       "         0.6109, 0.3152, 0.7175, 0.8365, 0.9794, 0.3690, 0.2469, 0.6974, 0.8714,\n",
       "         0.9373],\n",
       "        [0.9411, 0.3888, 0.6196, 0.8046, 0.8760, 0.9046, 0.3740, 0.1897, 0.5870,\n",
       "         0.5435, 0.8730, 0.1238, 0.6750, 0.6954, 0.0066, 0.1248, 0.7815, 0.1443,\n",
       "         0.1178, 0.5725, 0.7544, 0.0951, 0.2124, 0.6303, 0.7260, 0.5990, 0.4326,\n",
       "         0.4698],\n",
       "        [0.0197, 0.4586, 0.6753, 0.1986, 0.4772, 0.9899, 0.8832, 0.2909, 0.1190,\n",
       "         0.7389, 0.1692, 0.6098, 0.6113, 0.1194, 0.0603, 0.7942, 0.9590, 0.2949,\n",
       "         0.6980, 0.3149, 0.6066, 0.9151, 0.9221, 0.2325, 0.5786, 0.5059, 0.6713,\n",
       "         0.9557],\n",
       "        [0.8991, 0.7553, 0.6739, 0.0071, 0.1542, 0.8046, 0.8658, 0.0415, 0.4493,\n",
       "         0.9066, 0.5877, 0.4951, 0.9507, 0.7048, 0.8390, 0.6896, 0.2345, 0.4415,\n",
       "         0.9912, 0.4091, 0.6972, 0.4192, 0.0016, 0.7531, 0.3045, 0.6961, 0.2502,\n",
       "         0.4143],\n",
       "        [0.3469, 0.4228, 0.1052, 0.2805, 0.8483, 0.8685, 0.3597, 0.9080, 0.6381,\n",
       "         0.0477, 0.9005, 0.7764, 0.9575, 0.0041, 0.9053, 0.9637, 0.5512, 0.8062,\n",
       "         0.7089, 0.0735, 0.9177, 0.6170, 0.8622, 0.6747, 0.5506, 0.1516, 0.0248,\n",
       "         0.8114],\n",
       "        [0.4220, 0.7034, 0.2108, 0.1571, 0.4407, 0.0800, 0.5780, 0.4753, 0.6816,\n",
       "         0.3401, 0.7916, 0.3079, 0.6757, 0.9961, 0.9940, 0.8545, 0.8505, 0.4430,\n",
       "         0.5590, 0.7345, 0.8330, 0.7819, 0.6625, 0.7029, 0.2279, 0.3456, 0.8904,\n",
       "         0.4017],\n",
       "        [0.0831, 0.2510, 0.8881, 0.3808, 0.4984, 0.8677, 0.5921, 0.0992, 0.5343,\n",
       "         0.6899, 0.5998, 0.3901, 0.8213, 0.8841, 0.0113, 0.7430, 0.9629, 0.1608,\n",
       "         0.2630, 0.7271, 0.6890, 0.0243, 0.9102, 0.1315, 0.3438, 0.2439, 0.3278,\n",
       "         0.7152],\n",
       "        [0.3411, 0.0957, 0.2809, 0.9705, 0.7820, 0.6669, 0.9927, 0.3337, 0.8425,\n",
       "         0.4151, 0.6095, 0.0870, 0.9852, 0.7779, 0.3404, 0.9269, 0.9255, 0.0176,\n",
       "         0.5530, 0.9872, 0.3460, 0.3780, 0.1984, 0.9308, 0.2875, 0.7381, 0.2640,\n",
       "         0.3436],\n",
       "        [0.3649, 0.1603, 0.2130, 0.8484, 0.7497, 0.3062, 0.3686, 0.7663, 0.6046,\n",
       "         0.0713, 0.5886, 0.4837, 0.8194, 0.0760, 0.9811, 0.6543, 0.2152, 0.7206,\n",
       "         0.5295, 0.6918, 0.0321, 0.4832, 0.1114, 0.3174, 0.9041, 0.2859, 0.3646,\n",
       "         0.1394],\n",
       "        [0.1830, 0.5146, 0.8269, 0.8518, 0.6843, 0.7766, 0.8937, 0.9750, 0.3765,\n",
       "         0.6177, 0.2560, 0.1431, 0.0477, 0.9476, 0.4581, 0.3469, 0.9936, 0.0012,\n",
       "         0.2774, 0.1944, 0.6723, 0.2392, 0.7723, 0.1353, 0.9836, 0.7909, 0.5068,\n",
       "         0.6513],\n",
       "        [0.9308, 0.5293, 0.1746, 0.9208, 0.9533, 0.6644, 0.3366, 0.3138, 0.9535,\n",
       "         0.5231, 0.3015, 0.4470, 0.9522, 0.1420, 0.9679, 0.3998, 0.0952, 0.0185,\n",
       "         0.2205, 0.4491, 0.2920, 0.1379, 0.4017, 0.4469, 0.8662, 0.2439, 0.2291,\n",
       "         0.9474],\n",
       "        [0.8336, 0.8618, 0.3075, 0.8395, 0.5116, 0.2850, 0.2599, 0.1676, 0.8307,\n",
       "         0.7186, 0.5550, 0.8273, 0.4210, 0.4687, 0.6552, 0.9510, 0.1576, 0.5572,\n",
       "         0.7119, 0.4856, 0.8525, 0.5810, 0.8015, 0.2242, 0.7555, 0.5878, 0.3705,\n",
       "         0.4371],\n",
       "        [0.3725, 0.7328, 0.6597, 0.1955, 0.6075, 0.8829, 0.7383, 0.4269, 0.7595,\n",
       "         0.0654, 0.7974, 0.7367, 0.3419, 0.7643, 0.0469, 0.4064, 0.0386, 0.9490,\n",
       "         0.3036, 0.6619, 0.7522, 0.2302, 0.2994, 0.6917, 0.1804, 0.3957, 0.5878,\n",
       "         0.2192],\n",
       "        [0.7996, 0.2083, 0.1865, 0.6309, 0.7401, 0.8912, 0.7433, 0.0732, 0.1759,\n",
       "         0.8991, 0.6787, 0.9540, 0.0697, 0.5392, 0.2538, 0.1302, 0.3691, 0.5916,\n",
       "         0.1487, 0.2370, 0.5383, 0.8190, 0.4975, 0.0493, 0.4594, 0.0307, 0.3840,\n",
       "         0.1597],\n",
       "        [0.6647, 0.5260, 0.3961, 0.2709, 0.0988, 0.4460, 0.3591, 0.3297, 0.4122,\n",
       "         0.3550, 0.2782, 0.1647, 0.3192, 0.1848, 0.7640, 0.4417, 0.0621, 0.6155,\n",
       "         0.4427, 0.6372, 0.7268, 0.3411, 0.7592, 0.7062, 0.9713, 0.5753, 0.3414,\n",
       "         0.2501],\n",
       "        [0.6307, 0.1836, 0.0132, 0.4384, 0.6504, 0.7942, 0.7204, 0.1778, 0.6669,\n",
       "         0.7931, 0.1064, 0.6147, 0.5705, 0.3770, 0.0519, 0.7258, 0.7076, 0.4569,\n",
       "         0.5999, 0.6819, 0.3924, 0.2604, 0.9867, 0.3992, 0.2260, 0.9826, 0.3601,\n",
       "         0.0550],\n",
       "        [0.4869, 0.1512, 0.1617, 0.1789, 0.7225, 0.3893, 0.9789, 0.8898, 0.5976,\n",
       "         0.1228, 0.7453, 0.4627, 0.3858, 0.8555, 0.2360, 0.1414, 0.0045, 0.4793,\n",
       "         0.4654, 0.7182, 0.5731, 0.2633, 0.9695, 0.9549, 0.1838, 0.1415, 0.5419,\n",
       "         0.0198],\n",
       "        [0.2311, 0.4807, 0.2354, 0.0361, 0.7452, 0.3780, 0.0993, 0.6226, 0.0077,\n",
       "         0.9531, 0.3187, 0.7212, 0.1087, 0.9541, 0.6940, 0.9312, 0.6371, 0.2902,\n",
       "         0.0073, 0.0942, 0.7916, 0.9012, 0.2223, 0.3755, 0.7726, 0.7521, 0.5751,\n",
       "         0.3470],\n",
       "        [0.4909, 0.3087, 0.6782, 0.9514, 0.6510, 0.7938, 0.7357, 0.5697, 0.2418,\n",
       "         0.0687, 0.5009, 0.6591, 0.8034, 0.5512, 0.7291, 0.5066, 0.0274, 0.6824,\n",
       "         0.0997, 0.4291, 0.6287, 0.4736, 0.5708, 0.6759, 0.1634, 0.8349, 0.6852,\n",
       "         0.0540],\n",
       "        [0.0225, 0.7816, 0.2045, 0.3805, 0.0527, 0.4034, 0.2893, 0.4434, 0.3188,\n",
       "         0.7247, 0.3877, 0.1372, 0.5862, 0.3933, 0.6877, 0.5828, 0.6994, 0.6912,\n",
       "         0.0524, 0.8284, 0.0125, 0.5744, 0.3609, 0.2331, 0.8637, 0.5043, 0.4097,\n",
       "         0.2453],\n",
       "        [0.6949, 0.2229, 0.9745, 0.8159, 0.5077, 0.5958, 0.0895, 0.4593, 0.9936,\n",
       "         0.8385, 0.0566, 0.7521, 0.7143, 0.1560, 0.3616, 0.1292, 0.7820, 0.8971,\n",
       "         0.3124, 0.5601, 0.8133, 0.6319, 0.4357, 0.2347, 0.6329, 0.2914, 0.8360,\n",
       "         0.6592],\n",
       "        [0.5036, 0.1590, 0.6730, 0.4142, 0.6993, 0.5138, 0.2855, 0.4532, 0.8879,\n",
       "         0.0920, 0.5236, 0.7503, 0.4589, 0.4354, 0.4004, 0.3042, 0.6322, 0.0392,\n",
       "         0.4166, 0.8360, 0.4931, 0.6054, 0.5588, 0.8266, 0.0962, 0.1267, 0.2287,\n",
       "         0.6665],\n",
       "        [0.0415, 0.6959, 0.6087, 0.0172, 0.1383, 0.9521, 0.6883, 0.7074, 0.2323,\n",
       "         0.1405, 0.6871, 0.4768, 0.3123, 0.8131, 0.3853, 0.0662, 0.5122, 0.3854,\n",
       "         0.6601, 0.4575, 0.5927, 0.3764, 0.1348, 0.8381, 0.4169, 0.3602, 0.5595,\n",
       "         0.0344],\n",
       "        [0.3214, 0.6391, 0.8735, 0.5062, 0.4325, 0.7646, 0.9659, 0.6269, 0.1394,\n",
       "         0.0210, 0.0344, 0.6199, 0.8055, 0.3382, 0.8895, 0.7550, 0.7423, 0.4822,\n",
       "         0.5524, 0.8662, 0.7838, 0.9026, 0.3042, 0.7452, 0.7336, 0.7192, 0.0598,\n",
       "         0.4775],\n",
       "        [0.3752, 0.5760, 0.5755, 0.0216, 0.1130, 0.4399, 0.1265, 0.2063, 0.5839,\n",
       "         0.7759, 0.5310, 0.0047, 0.5932, 0.4144, 0.5201, 0.6224, 0.3713, 0.6178,\n",
       "         0.5670, 0.6255, 0.3209, 0.8490, 0.0051, 0.3716, 0.6974, 0.0197, 0.8797,\n",
       "         0.0438]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(-1, 28*28) #-1 specifies the batch can be of any size, else you specfiy the batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.0118, grad_fn=<NllLossBackward>)\n",
      "loss tensor(0.0095, grad_fn=<NllLossBackward>)\n",
      "loss tensor(0.3851, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001) #net.parameters correspond to all things that are adjustable\n",
    "#learning ratedecides size of the step, decaying learning rate is helpful\n",
    "\n",
    "EPOCHS = 3 #number of whole passes\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        #data is a batch of features and labels\n",
    "        X, y = data\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        loss = F.nll_loss(output,y) #if data is not a one hot vector, then use nll_loss, else use mean squared error\n",
    "        loss.backward() #backpropagate loss\n",
    "        optimizer.step()\n",
    "    print('loss',loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.979\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,28*28))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"accuracy:\", round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[3].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
